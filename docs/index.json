[{"authors":null,"categories":null,"content":"Hi üëã! I\u0026rsquo;m Luca Corbucci, a Ph.D. candidate in Computer Science at the University of Pisa. My main research interests are Explainable AI, Federated Learning and privacy risks in federated learning.\nI received a B.Sc. degree in Computer Science in 2018 and a M.Sc. degree in Computer Science with a thesis about \u0026ldquo;Semantic enrichment of XAI explanations for healthcare\u0026rdquo;.\nIn 2019 I spent one semester at the Computer Science Departement of the Technische Universit√§t M√ºnchen as exchange student thanks to the Erasmus program.\nI\u0026rsquo;m the co-founder of \u0026ldquo;PointerPodcast\u0026rdquo; and the co-founder of \u0026ldquo;SuperHeroesValley\u0026rdquo;, a community that organize meetups for ambitious CS students to build a bridge between university and big tech companies.\n Download my resum√©--- ","date":1611532800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1611532800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Hi üëã! I\u0026rsquo;m Luca Corbucci, a Ph.D. candidate in Computer Science at the University of Pisa. My main research interests are Explainable AI, Federated Learning and privacy risks in federated learning.","tags":null,"title":"Luca Corbucci","type":"authors"},{"authors":["Luca Corbucci"],"categories":null,"content":"","date":1618484400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618484400,"objectID":"14e64fd89945af81358b7067713fdd1c","permalink":"https://lucacorbucci.me/talk/natural-language-processing-nel-campo-healthcare-storia-della-mia-tesi/","publishdate":"2021-04-15T11:00:00Z","relpermalink":"/talk/natural-language-processing-nel-campo-healthcare-storia-della-mia-tesi/","section":"event","summary":"Una breve presentazione della mia tesi tenuta durante l'evento Incontra Informatica","tags":["2021"],"title":"Natural Language Processing nel campo Healthcare: storia della mia tesi","type":"event"},{"authors":null,"categories":null,"content":"Tech Stack: Python, Matplotlib, Pandas, Keras, Streamlit, Docker\nThe repository contains all the milestones implemented during the course \u0026ldquo;Big Data Analytics\u0026rdquo; @ the University of Pisa. The team that worked on this project is the \u0026ldquo;MaLuCS\u0026rdquo; team which was composed by:\n Luca Corbucci Cinzia Lestini Marco Giuseppe Marino Simone Rossi  The goal of course was to develop a big data analytics project. The projects were based on real-world datasets covering several thematic areas.\nThe project is divided into 3 main milestones:\n Data Understanding and Project Formulation Model(s) construction and evaluation Model interpretation/explanation  At the end of each of these milestones, we presented our results and we wrote a report. At the end of the course, we developed a final notebook to show the results reached during all the midterm.\nFolder structure There is a folder for each Midterm, in each of these folders you can find a Jupyter Notebook, a dataset and the slides of the presentation. There is a folder called \u0026ldquo;Final Term\u0026rdquo; that contains the final notebook and the code of the Streamlit web app. There is a folder called \u0026ldquo;Report\u0026rdquo; which contains the report we wrote for the exam.\nFinal Term Notebook Inside the Jupyter notebook you can find all the most important task of our project:\n Data Cleaning: this part was developed during the first Midterm. Prediction: this part was developed during the second Midterm. Explanation: this part was developed during the third Midterm.  Streamlit We developed a simple web app using Streamlit to visualize our work.\nIn the web app, you can upload the sample dataset and then you will see the same pieces of information that you can compute in the notebook.\nIn the bottom of the page, you can select an instance of the dataset to see the explanation.\nYou can visualize the web app using this link: http://62.171.188.29:8501/.\nAlternatively, you can host on your own computer, we used Docker to simplify the execution of this service: Run Streamlit using Docker\nRun docker-compose up in your terminal to run src/main.py in Streamlit, then open localhost:8501/ in your browser to visualize our project.\n","date":1610582400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1610582400,"objectID":"4684dd878208f95ec7ad016b9cd9c208","permalink":"https://lucacorbucci.me/project/bigdataanalytics/","publishdate":"2021-01-14T00:00:00Z","relpermalink":"/project/bigdataanalytics/","section":"project","summary":"Implementation of all the milestones of the Big Data Analytics course","tags":["University"],"title":"Flu Shot Learning: Predict H1N1 and Seasonal Flu Vaccines","type":"project"},{"authors":null,"categories":null,"content":"Tech Stack: Python, Matplotlib, Pandas, Keras\nWe joined the competition \u0026ldquo;Real or Not? NLP with Disaster Tweets\u0026rdquo; during an exam at the University. We developed and evaluated several machine learning models that had the aim to classify tweet as real disaster or unreal disaster.\nIn particular we trained the following models:\n Naive Bayes LSTM Bidirectional LSTM Bert  We used keras to develop the models.\n","date":1592179200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592179200,"objectID":"8e57a7660cadc1931b7a89f2a301cf97","permalink":"https://lucacorbucci.me/project/nlp/","publishdate":"2020-06-15T00:00:00Z","relpermalink":"/project/nlp/","section":"project","summary":"A kaggle competition to get started with NLP.","tags":["University"],"title":"Real or Not? NLP with Disaster Tweets","type":"project"},{"authors":["Luca Corbucci","Alessandro Berti","Eugenio Paluello"],"categories":null,"content":"","date":1588442400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588442400,"objectID":"8148cbebd932d1060967191767db9efd","permalink":"https://lucacorbucci.me/talk/blockchain-smart-contract-from-scratch/","publishdate":"2020-05-02T18:00:00Z","relpermalink":"/talk/blockchain-smart-contract-from-scratch/","section":"event","summary":"A short introduction about Blockchain and how to develop a Smart Contract","tags":["2020"],"title":"Blockchain: Smart Contract From Scratch","type":"event"},{"authors":["Luca Corbucci","Alessandro Berti","Eugenio Paluello"],"categories":null,"content":"","date":1586023200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586023200,"objectID":"d8f05bc10495cd46c768122e3fd19c75","permalink":"https://lucacorbucci.me/talk/how-to-start-a-podcast/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/how-to-start-a-podcast/","section":"event","summary":"A short introduction about how to start a podcast.","tags":["2020"],"title":"How to start a Podcast","type":"event"},{"authors":null,"categories":null,"content":"Tech Stack: React, Solidity\nPointerDapp is a simple application that we developed to show you one possible use case of the Blockchain.\nWe developed a distributed chat, you can create (or delete) groups and you can send and receive messages.\nWe presented our work during the GDG DevParty Together 2020, you can see here the video of our talk (in italian). Slides are available here\n  Alessandro Berti\nüë®‚Äçüíª Luca Corbucci\nüë®‚Äçüíª Eugenio Paluello\nüë®‚Äçüíª   Code üë©‚Äçüíª In this repo you can find two main folders:\n smart_contract: this folder contains the solidity code of the two contracts we wrote. frontend: this folder contains the frontend code written using ReactJS.  How to try PointerDapp üöÄ You can try our application using the following link: http://pointerdapp.it:3000.\nTo try our application you need to install Metamask in your browser, you can use this extension in Chrome, Firefox and Brave https://metamask.io.\nOur smart contracts are deployed on the Rinkeby test net, to use all the features of the distributed application you need an address and you have to charge your account using this link.\nContributing This is a project that we developed for the GDG DevParty, Feel free to open issues/pull requests to help us improve this project.\n","date":1585699200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585699200,"objectID":"6703e3bb009401d0178625d8ecae9d3a","permalink":"https://lucacorbucci.me/project/ethereumchat/","publishdate":"2020-04-01T00:00:00Z","relpermalink":"/project/ethereumchat/","section":"project","summary":"PointerDapp is a simple application that we developed to show you one possible use case of the Blockchain.","tags":["Personal"],"title":"PointerDapp - Ethereum Chat","type":"project"},{"authors":null,"categories":null,"content":"Tech Stack: Java, Git, Junit\nThis repository contains all the milestones implemented during the course \u0026ldquo;Advanced Practical Course: Cloud Data Bases\u0026rdquo; @ Technische Universit√§t M√ºnchen.\nThe goal of this practical course was to develop a Distributed Database using Java.\nMilestone 1 ‚úÖ The objective of this assignment is to implement a simple client program that is able to establish a TCP connection to a given server and exchange text messages with it. The client should provide a command line-based interface that captures the user‚Äôs input and controls the interaction with the server. Besides connection establishment and tear down, the user must be able to pass messages to the server. These messages are in turn echoed back to the client where they are displayed to the user. A sequence of interactions is shown below.\nEchoClient\u0026gt; connect clouddatabases.i13.in.tum.de 5153 EchoClient\u0026gt; Connection to MSRG Echo server established: /ddd.aaa.dd.xx / 5153 EchoClient\u0026gt; send hello world EchoClient\u0026gt; hello world EchoClient\u0026gt; disconnect EchoClient\u0026gt; Connection terminated: ddd.aaa.dd.xx / 5153 EchoClient\u0026gt; send hello again EchoClient\u0026gt; Error! Not connected! EchoClient\u0026gt; quit EchoClient\u0026gt; Application exit!  The assignment serves to refresh or establish basic knowledge of TCP-based network programming using Java stream sockets, mostly from the client‚Äôs perspective. This embodies concepts such as client/server architecture, network streams, and message serialization.\nDuring the first milestone I implemented the following features:\n TestClient, TestSendWrongMessage, TestSendEmptyMessage, TestSomething Signal Handling Connection/Disconnection of the client  Milestone 2 ‚úÖ The objective of this assignment is to implement a simple storage server that persists data to disk (e.g., a file). In addition, a small fraction of the data, i.e., a configurable number of key- value pairs can be cached in the servers‚Äô main memory. The storage server should provide the typical key-value query interface. To achieve this objective, the echo client from Assignment 1 should be extended to be able to communicate with the storage server and query it. These tasks require the development of an applicable communication protocol and a suitable message format. In this assignment, a single storage server will serve requests from multiple clients, whereas in the next assignment, we‚Äôll experiment with deploying a number of storage servers based on the artifacts developed in this and the previous assignment.\nDuring the second milestone I implemented the following features:\n Cache with Tests Storage on Disk and Tests Restore of data in case of shutdown Some other Tests  Milestone 3 ‚úÖ The objective of this assignment is to extend the storage server architecture from Milestone 2 into a elastic, scalable storage service (cf. the figure below). Data records (i.e., key-value pairs) are distributed over a number of storage servers by exploiting the capabilities of consistent hashing. A single storage server is only responsible for a subset of the whole data space (i.e., a range of successive hash values.) The hash function is used to determine the location of particular tuples (i.e., hash values of the associated keys).\nDuring the third milestone I implemented the following features:\n Metadata Module with Tests ECS Module with Tests Thread Pinger IntraCommunicationThread Some tests Part of the Enron Test  Milestone 4 ‚úÖ The objective of this assignment is to extend the storage service from Milestone 3 by means of replication. Data records (i.e., key-value pairs) are still distributed over a bunch of storage servers via consistent hashing. However, the storage servers are no longer just responsible for their own subset of the data, but also serve as replicas for data items of other servers. In this sense, a storage server assumes different roles for different tuples. A storage server may be a\n Coordinator node, if it is directly responsible for the tuple, following the concept of consistent hashing. This means it has a position in the ring, such that it is the closest successor server in the ring topology according to the tuple position (cf. Milestone 3). Or a replica node, if the tuple is coordinated by another storage node and the data is just replicated on this node. It is either replica_1 if it is first successor of the coordinator or replica_2 if it is the second successor. Each data item should be replicated exactly on the two storage servers that are following the coordinator node in the ring topology. Replication is invoked and managed by the coordinator node. This means that at least 3 active and responsive storage servers are needed. As long as just 1 or 2 nodes are in the system, no replication is used. The focus of this milestone is to implement a replication strategy that guarantees eventual consistency. It should also provide a reconciliation mechanism for topology changes. So far (as completed in Milestone 3) the key ranges are rebalanced. In this milestone als the replication is rebalanced when the topology changes.  During the forth milestone I implemented the following features:\n Replica of the K,V pairs with Tests Eventual Consistency PingThread Some Tests  Milestone 5 ‚úÖ The goal of this assignment is to extend the distributed database that we wrote in the previous milestone adding new features. I added the possibility to protect a key,value pair using a password. All the previously developed API (PUT, GET, DELETE) now supports the password protection.\n","date":1580083200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580083200,"objectID":"31f354bf77d3f3b7eb6669b40a2bc1bd","permalink":"https://lucacorbucci.me/project/clouddatabase/","publishdate":"2020-01-27T00:00:00Z","relpermalink":"/project/clouddatabase/","section":"project","summary":"Implementation of all the milestones of the Advanced Practical Course \"Cloud Data Bases\" @TUM Department of Informatics","tags":["University"],"title":"Advanced Practical Course Cloud DataBases","type":"project"},{"authors":null,"categories":null,"content":"Tech Stack: Python, MQTT, MongoDB, Flask, Docker, Flutter\nThis is a personal project I\u0026rsquo;ve developed using a NODEMCU (ESP88266) and a temperature sensor DHT22. The sensor detects the temperature and sends the data to a RaspberryPi using MQTT. The RaspberryPi stores the data in a local database and then sends the data to a VPS. On the VPS the temperature data is stored in a database and I developed a Flask API to access them. I\u0026rsquo;m currently using Flutter to visualize the data.\n","date":1569888000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569888000,"objectID":"532a297950d2642fcf04f0f8d393e933","permalink":"https://lucacorbucci.me/project/espweatherstation/","publishdate":"2019-10-01T00:00:00Z","relpermalink":"/project/espweatherstation/","section":"project","summary":"Homemade temperature sensor","tags":["Personal"],"title":"ESPWeatherStation","type":"project"},{"authors":null,"categories":null,"content":"Tech Stack: C++, FastFlow\nThis is the final project of the course \u0026ldquo;Parallel and Distributed Systems: Paradigms and Models\u0026rdquo; at the University of Pisa.\nAutonomic-Farm-Pattern Description The goal is to provide a farm pattern ensuring (best effort) a given service time leveraging on dynamic variation of the parallelism degree. The farm is instantiated and run by providing:\n A collection of input tasks to be computed (of type Tin) A function\u0026lt;Tout(Tin)\u0026gt; computing the single task An expected service time TSgoal An initial parallelism degree nw  During farm execution, autonomic farm management should increase or decrease the parallelism degree in such a way its service time is as close as possible to the expected service time TSgoal. The pattern should be tested providing a collection of tasks such that the tasks in the initial, central and final part all require a different average time to be computed (e.g. 4L in the first part, L in the second part and 8L in the third part) and the task collection execution time is considerably longer than the time needed to reconfigure the farm.\n","date":1536537600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536537600,"objectID":"c358ad53383c38fc21c79681a364bda6","permalink":"https://lucacorbucci.me/project/autonomicfarm/","publishdate":"2018-09-10T00:00:00Z","relpermalink":"/project/autonomicfarm/","section":"project","summary":"Parallel and Distributed Systems: Paradigms and Models Final Project (2018-19). Master Degree in Computer Science @ University of Pisa","tags":["University"],"title":"Autonomic Farm Pattern","type":"project"},{"authors":null,"categories":null,"content":"Tech Stack: C\nOperating Systems and Laboratory Project @ Unipi. Academic year 2016/2017.\nThe text of the project is available here: http://didawiki.di.unipi.it/doku.php/informatica/sol/laboratorio17/progetto and in the \u0026ldquo;Testo Progetto\u0026rdquo; folder in the repo. A final report is available in the \u0026ldquo;Report\u0026rdquo; folder.\nHow to try Chatterbox To test the project:\ngit clone https://github.com/lucacorbucci/ChatterBox.git cd Chatterbox make  Then you can launch the server using the command:\n./chatty -f ./DATA/chatty.conf1  You can run the client using the following command:\n./client -l /tmp/chatty_socket -c luca  There are some flags useful to configure and use the client.\nTest In the folder Test you can find some tests that can be used to try the Project.\n","date":1469577600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1469577600,"objectID":"c7b8e24776b9bc6cb81787b068e70dbc","permalink":"https://lucacorbucci.me/project/sistemioperativi/","publishdate":"2016-07-27T00:00:00Z","relpermalink":"/project/sistemioperativi/","section":"project","summary":"Operating System Project (2016-17). Bachelor Degree in Computer Science @ University of Pisa.","tags":["University"],"title":"ChatterBox","type":"project"},{"authors":null,"categories":null,"content":"Tech Stack: Solidity, React\nThis repo contains the final term and the final project developed for the \u0026ldquo;Peer to Peer Systems and Blockchains\u0026rdquo; course. I developed this in June 2019.\nA demo of the final project is available Here, you need to install metamask to use the site and to do the calls to the contracts.\nContracts In the \u0026ldquo;Contracts\u0026rdquo; folder there is the final term of the course, i put here the contracts written in Solidity. There are two contracts, one for the english Auction and one for the Vickrey Auction. Into the folder \u0026ldquo;Contracts\u0026rdquo; there is another readme where i explain the methods of the contracts and how to deploy it using Truffle.\nFrontend. In the \u0026ldquo;Frontend\u0026rdquo; folder there are a lot of files, i put here the auction contracts and also another contract that i wrote in solidity to store in the blockchain the address of the deployes contracts. I also changed the original Vickrey and English auction contracts based on the calls that i need to do from the frontend. There are also all the components that i wrote to build the frontend of the distributed application. For the frontend i used React and Bulma as CSS Framework.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"595b1398d223dd58a18683bf73aa7202","permalink":"https://lucacorbucci.me/project/blockchain/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/blockchain/","section":"project","summary":"Final Term - Peer to Peer Systems and Blockchains (2018-19). Master Degree in Computer Science @ University of Pisa .","tags":["University"],"title":"SmartAuctions","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://lucacorbucci.me/slides/example/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"","tags":null,"title":"","type":"slides"}]